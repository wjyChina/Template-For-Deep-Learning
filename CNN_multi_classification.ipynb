{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_multi_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wjyChina/Template-For-Deep-Learning/blob/master/CNN_multi_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5s8bG8BRfcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import numpy as np  #linear algebra\n",
        "import pandas as pd #Only CSV IO\n",
        "import os\n",
        "import re\n",
        "from torch.utils import data #dataloader of batch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import metrics\n",
        "from torch.autograd import Variable #We can ask require grad or not\n",
        "from torch.optim.optimizer import Optimizer\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTtD6cPmSC-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Mount Google drive to gain access to data in it ###\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja6UZCroSDqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Change here ###\n",
        "### Mount the folder of your data. You can use !ls to check all the folders in your current path ###\n",
        "os.chdir(\"drive/My Drive/Colab Notebooks/\") \n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK150aqSSF8E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Change here ###\n",
        "### Read in your data ###\n",
        "data=pd.read_csv('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A90oRgtTWxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Change here ###\n",
        "### Split your data by data_y. First you need to split the original data into input and target ###\n",
        "data_x=\n",
        "data_y=\n",
        "x_train,x_test,y_train,y_test = train_test_split(data_x,data_y,test_size=0.25,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD3ESkjNTYtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train=np.array(x_train)\n",
        "y_train=np.array(y_train)\n",
        "x_test=np.array(x_test)\n",
        "y_test=np.array(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ry2ikTTi0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Change here ###\n",
        "### Hyperparameters for training ###\n",
        "seed = 1\n",
        "learning_rate = 0.001\n",
        "batch_size = 1024\n",
        "n_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pc_P14UXCQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Change here ###\n",
        "### CNN_2D ###\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 =  nn.Conv2d(1, 32,    kernel_size=3, stride=(1,1), padding=2) ## 28+2*2-3+1=30\n",
        "        \n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=(2,2),padding=0)  ## (30 -2)/2+1=15\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(32,128, kernel_size=5,stride=(1,1),padding=2) ## (15+2*2-5)+1=15\n",
        "        \n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=(2,2),padding=0) ## (15-2)/2+1=7\n",
        "        \n",
        "        self.conv3 = nn.Conv2d(128,64,kernel_size=3,stride=(1,1),padding=1) ## (7+2-3)+1=7\n",
        "        \n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2,stride=(2,2),padding=0) ## (7-2)/2+1=3\n",
        "                                                                        ## 3*3*64\n",
        "        self.linear1 = nn.Linear(3*3*64,1024)\n",
        "        \n",
        "        self.linear2 = nn.Linear(1024,256)\n",
        "        \n",
        "        self.linear3 = nn.Linear(256, num_classes)  \n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        out = self.conv1(x)\n",
        "        out = F.relu(out)\n",
        "        out = self.pool1(out)\n",
        "        \n",
        "        out = self.conv2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.pool2(out)\n",
        "        \n",
        "        out = self.conv3(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.pool3(out)\n",
        "        \n",
        "        out=out.view(-1,3*3*64)\n",
        "        out = self.linear1(out)\n",
        "        out = F.relu(out)\n",
        "        \n",
        "        out = self.linear2(out)\n",
        "        out = F.relu(out)\n",
        "        \n",
        "        out = self.linear3(out)\n",
        "        \n",
        "        logits = out\n",
        "        probas = F.softmax(logits, dim=1)\n",
        "        return logits, probas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye7qIA7Zbkqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### CNN 1D with concatenating and embedding. Binary ###\n",
        "class CNN_1D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNet2, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.embedding = nn.Embedding(embedding_size,max_word)    \n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix_1, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.embedding_dropout = SpatialDropout(0.15)\n",
        "         \n",
        "        self.pool = nn.MaxPool1d(4)\n",
        "        \n",
        "        self.branch1 = nn.Conv1d(300,128,3)   #Conv1D takes batch*channel*width     \n",
        "        self.branch2 = nn.Conv1d(300,128,4)\n",
        "        self.branch3 = nn.Conv1d(300,128,5)\n",
        "        \n",
        "        self.bn_branch = nn.BatchNorm1d(128)\n",
        "        self.bn_2 = nn.BatchNorm1d(64)\n",
        "        \n",
        "        self.conv_1=nn.Conv1d(128,64,5)\n",
        "        self.linear=nn.Linear(576,256)\n",
        "        self.linear2=nn.Linear(256,1)\n",
        "      \n",
        "    def forward(self, x):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_embedding = self.embedding_dropout(h_embedding)\n",
        "        h_embedding = torch.transpose(h_embedding,1,2) \n",
        "        \n",
        "        branch1=self.branch1(h_embedding)\n",
        "        branch1=self.bn_branch(branch1)\n",
        "        branch1=F.relu(branch1)\n",
        "        branch1 = F.dropout(branch1,p=0.2,training=self.training)\n",
        "        branch1=self.pool(branch1)\n",
        "        branch2=self.branch2(h_embedding)\n",
        "        branch2=self.bn_branch(branch2)\n",
        "        branch2=F.relu(branch2)\n",
        "        branch2 = F.dropout(branch2,p=0.2,training=self.training)\n",
        "        branch2=self.pool(branch2)\n",
        "        branch3=self.branch3(h_embedding)\n",
        "        branch3=self.bn_branch(branch3)\n",
        "        branch3=F.relu(branch3)\n",
        "        branch3 = F.dropout(branch3,p=0.2,training=self.training)\n",
        "        branch3=self.pool(branch3)\n",
        "        cat=torch.cat([branch1,branch2,branch3],2)\n",
        "        out=self.conv_1(cat)\n",
        "        out=self.bn_2(out)\n",
        "        out=F.relu(out)\n",
        "        out=F.dropout(out,p=0.2,training=self.training)\n",
        "        out=self.pool(out)\n",
        "        out=out.view(-1,576)\n",
        "        out=self.linear(out)\n",
        "        out=F.relu(out)\n",
        "        out=self.linear2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eRbdCCxTjku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Change here if you are going to use loss function other than Cross Entropy ###\n",
        "def compute_epoch_loss(model, data_loader):\n",
        "    curr_loss, num_examples = 0., 0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in data_loader:\n",
        "            features = features.view(-1, 784).to(device)\n",
        "            targets = targets.to(device)\n",
        "            logits, probas = model.forward(features)\n",
        "            loss = F.cross_entropy(logits, torch.squeeze(targets), reduction='sum')\n",
        "            num_examples += targets.size(0)\n",
        "            curr_loss += loss\n",
        "\n",
        "        curr_loss = curr_loss / num_examples\n",
        "        return curr_loss\n",
        "\n",
        "    \n",
        "def compute_accuracy(model, data_loader):\n",
        "    correct_pred, num_examples = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for features, targets in data_loader:\n",
        "            features = features.view(-1, 784).to(device)\n",
        "            targets = targets.to(device)\n",
        "            targets = torch.squeeze(targets)\n",
        "            logits, probas = model.forward(features)\n",
        "            predicted_labels = torch.argmax(probas, 1)\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "        return correct_pred.float()/num_examples * 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnv7R1PZVy8U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainfoldx = torch.tensor(x_train, dtype=torch.float32).to(device)\n",
        "trainfoldy = torch.tensor(y_train, dtype=torch.long).to(device)\n",
        "x_val_fold = torch.tensor(x_test, dtype=torch.float32).to(device)\n",
        "y_val_fold = torch.tensor(y_test[:,np.newaxis], dtype=torch.long).to(device)\n",
        "\n",
        "train = torch.utils.data.TensorDataset(trainfoldx,trainfoldy)\n",
        "valid = torch.utils.data.TensorDataset(x_val_fold, y_val_fold)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train , batch_size=batch_size,shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AAotBVDWOav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mbatch_cost = []\n",
        "start_time = time.time()\n",
        "minibatch_cost = []\n",
        "epoch_cost = []  \n",
        "torch.manual_seed(seed)\n",
        "model = CNN()                   ### Change here if your model name is changed ###\n",
        "model.to(device)                \n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001, weight_decay=1e-8)  ### Change here for different optimizer ###\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "    grand_loss = 0\n",
        "    for  batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        logits, probas = model(x_batch)\n",
        "        loss = F.cross_entropy(logits, y_batch)\n",
        "\n",
        "        #backprop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        mbatch_cost.append(loss.item())\n",
        "        grand_loss += loss.item()/len(train_loader)\n",
        "        if not batch_idx % 50:\n",
        "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Loss: %.4f' \n",
        "                %(epoch+1, n_epochs, batch_idx, len(train_loader), loss.item()))\n",
        "\n",
        "                  #evaluation          \n",
        "    model.eval()\n",
        "    cost = compute_epoch_loss(model, train_loader)\n",
        "    cost_test = compute_epoch_loss(model, valid_loader)\n",
        "    epoch_cost.append(cost)\n",
        "\n",
        "    train_accuracy = compute_accuracy(model, train_loader)\n",
        "    valid_accuracy = compute_accuracy(model, valid_loader)\n",
        "\n",
        "    print('Epoch: %03d/%03d Train Cost: %.4f Test Cost: %.4f' % (\n",
        "            epoch+1, n_epochs, cost, cost_test))\n",
        "    print('Train Accuracy: %.3f | Test Accuracy: %.3f' % (train_accuracy, valid_accuracy))\n",
        "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
        "\n",
        "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWhGIAKjYrqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Plot minibatch v.s. loss ###\n",
        "plt.plot(mbatch_cost)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M1KabuQYuBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Get prediction and model judgement metrics ###\n",
        "logits, predicted_prob = model(x_val_fold)\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, np.array(predicted_prob.detach().cpu()))\n",
        "plt.plot(fpr, tpr, 'b')\n",
        "plt.plot([0, 1], [0, 1], 'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('TP')\n",
        "plt.xlabel('FP')\n",
        "plt.show()\n",
        "AUC = metrics.auc(fpr, tpr)\n",
        "print('AUC=',AUC)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "pred = torch.argmax(predicted_prob, 1)\n",
        "con=confusion_matrix(y_test,pred)\n",
        "accuracy=(con[0,0]+con[1,1])/(con[0,1]+con[1,0]+con[0,0]+con[1,1])\n",
        "precision=con[0,0]/(con[0,0]+con[1,0])\n",
        "recall=con[0,0]/(con[0,0]+con[0,1])\n",
        "print('accuracy=',accuracy)\n",
        "print('error=',1-accuracy)\n",
        "print('precision=',precision)\n",
        "print('recall=',recall)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}